# ðŸš€ EXAI MCP Server: Ultimate Agent Handoff Guide
**Date:** 2025-10-19  
**Status:** ACTIVE - Ready for Next Agent  
**Session Summary:** 8 Critical Bugs Fixed, System Stabilized, Systematic Methodology Established

---

## ðŸ“‹ TABLE OF CONTENTS
1. [EXAI Tool Mastery](#1-exai-tool-mastery)
2. [Systematic Debugging Methodology](#2-systematic-debugging-methodology)
3. [Critical Mindset: The Investigative Approach](#3-critical-mindset-the-investigative-approach)
4. [Current System State](#4-current-system-state)
5. [Practical Workflow Examples](#5-practical-workflow-examples)
6. [Emergency Procedures](#6-emergency-procedures)
7. [Success Metrics](#7-success-metrics)

---

## 1. EXAI Tool Mastery

### ðŸ› ï¸ Available Tools & When to Use Them

**Workflow Tools (Multi-Step Investigation):**

âš ï¸ **CRITICAL WARNING (Bug #10):** ALL workflow tools share the same infinite loop vulnerability. The circuit breaker detects confidence stagnation but DOES NOT ABORT. Use with caution and monitor Docker logs!

- **`debug_EXAI-WS`**: Root cause investigation for bugs and errors
  - âš ï¸ **WARNING: Can loop infinitely if confidence stagnates - monitor logs!**
  - Use when: Tracking down mysterious errors, understanding failure pathways
  - Params: `step`, `findings`, `hypothesis`, `relevant_files`, `confidence`
  - Best for: Systematic bug hunting with evidence-based reasoning
  - **Workaround:** Set `confidence="certain"` when you have clear findings to force early termination

- **`codereview_EXAI-WS`**: Comprehensive code quality analysis
  - âš ï¸ **WARNING: Can loop infinitely if confidence stagnates - monitor logs!**
  - Use when: Reviewing code for issues, security, performance
  - Params: `step`, `findings`, `relevant_files`, `review_type`
  - Best for: Pre-commit validation, security audits
  - **Workaround:** Set `confidence="certain"` when review is complete to force early termination

- **`analyze_EXAI-WS`**: Strategic architectural assessment
  - âš ï¸ **WARNING: Can loop infinitely if confidence stagnates - monitor logs!**
  - Use when: Understanding system architecture, design decisions
  - Params: `step`, `findings`, `relevant_files`, `analysis_type`
  - Best for: High-level system understanding, refactoring planning
  - **Workaround:** Set `confidence="certain"` when analysis is complete to force early termination

- **`thinkdeep_EXAI-WS`**: Extended hypothesis-driven reasoning
  - âš ï¸ **WARNING: MOST AFFECTED by infinite loop bug - DO NOT USE**
  - Use when: ~~Complex problems requiring deep analysis~~ **Use chat_EXAI-WS instead**
  - Params: `step`, `findings`, `hypothesis`, `problem_context`
  - Best for: ~~Architectural decisions, complex trade-offs~~ **BROKEN - needs fix**
  - Status: Bug #9/#10 - Auto-execution loops endlessly with "Confidence stagnant"

**Simple Tools (Single-Turn):**
- **`chat_EXAI-WS`**: General communication and quick questions
  - Use when: Quick consultations, explanations, brainstorming
  - Params: `prompt`, `files`, `images`, `model`
  - Best for: Fast feedback, file analysis, general questions

### âš™ï¸ Critical Tool Usage Rules

**ALWAYS:**
- âœ… Use `model="glm-4.6"` for better performance and reliability
- âœ… Set `use_websearch=false` unless you need current documentation
- âœ… Pass `relevant_files` as FULL absolute paths: `c:\\Project\\EX-AI-MCP-Server\\tools\\chat.py`
- âœ… Monitor for WebSocket drops (`no close frame received or sent`) and retry
- âœ… Check Docker logs after EVERY tool call to verify behavior
- âœ… Use `continuation_id` for multi-turn conversations to preserve context

**NEVER:**
- âŒ Use workflow tools without checking Docker logs afterward
- âŒ Ignore WebSocket connection drops - they indicate issues
- âŒ Pass large code snippets in `step` parameter - use `relevant_files` instead
- âŒ Use `model="auto"` - it can cause extended hang times
- âŒ Assume a tool succeeded without verifying the output

### ðŸŽ¯ Tool Selection Decision Tree

```
Is it a bug/error investigation?
â”œâ”€ YES â†’ Use debug_EXAI-WS (âš ï¸ MONITOR LOGS - can loop infinitely!)
â”‚        Alternative: Use chat_EXAI-WS for safer debugging
â””â”€ NO â†’ Is it code quality/security review?
    â”œâ”€ YES â†’ Use codereview_EXAI-WS (âš ï¸ MONITOR LOGS - can loop infinitely!)
    â”‚        Alternative: Use chat_EXAI-WS for safer review
    â””â”€ NO â†’ Is it architectural analysis?
        â”œâ”€ YES â†’ Use analyze_EXAI-WS (âš ï¸ MONITOR LOGS - can loop infinitely!)
        â”‚        Alternative: Use chat_EXAI-WS for safer analysis
        â””â”€ NO â†’ Is it a quick question OR complex reasoning?
            â”œâ”€ YES â†’ Use chat_EXAI-WS (SAFEST OPTION)
            â””â”€ NO â†’ Use chat_EXAI-WS (seriously, it's the most reliable)
```

**ðŸš¨ CRITICAL WARNING (Bug #10):** ALL workflow tools (debug, codereview, analyze, thinkdeep) have an infinite loop vulnerability. The circuit breaker detects confidence stagnation but DOES NOT ABORT.

**Recommendation:**
- **SAFEST:** Use `chat_EXAI-WS` for all tasks until Bug #10 is fixed
- **IF using workflow tools:** Monitor Docker logs closely for "Confidence stagnant" warnings
- **WORKAROUND:** Set `confidence="certain"` when you have clear findings to force early termination
- **NEVER use thinkdeep** - it's the most affected by this bug

### ðŸ“ Example Tool Usage

**Good Approach:**
```python
# Step 1: Use debug tool to investigate
debug_EXAI-WS(
    step="Investigate path normalization failure in workflow tools",
    findings="Docker logs show '/app/c:\\Project\\...' instead of '/app/tools/...'",
    hypothesis="Path normalization regex not matching Windows paths correctly",
    relevant_files=["c:\\Project\\EX-AI-MCP-Server\\tools\\workflow\\performance_optimizer.py"],
    model="glm-4.6",
    confidence="medium"
)

# Step 2: Check Docker logs
docker logs exai-mcp-daemon --tail 100 | grep "path\|normalize"

# Step 3: Implement fix based on findings
# Step 4: Rebuild container
# Step 5: Test with actual Windows path
# Step 6: Verify in Docker logs
```

**Bad Approach:**
```python
# Just guessing without investigation
chat_EXAI-WS(prompt="How do I fix path normalization?")
# No Docker log verification
# No testing
# Moving on to next task
```

---

## 2. Systematic Debugging Methodology

### ðŸ” The 7-Step Process (NON-NEGOTIABLE)

```
1. INVESTIGATE
   â†“ Thoroughly examine the issue without assumptions
   â†“ Check Docker logs for error patterns
   â†“ Trace code pathways through multiple files
   â†“ Reproduce the issue if possible
   
2. CONSULT EXAI
   â†“ Use appropriate tool (debug/codereview/analyze)
   â†“ Provide comprehensive context and evidence
   â†“ Ask specific, targeted questions
   
3. FIX
   â†“ Implement targeted solution based on findings
   â†“ Make minimal, focused changes
   â†“ Document the fix in code comments
   
4. REBUILD
   â†“ docker-compose down
   â†“ docker-compose up -d --build
   â†“ Wait for container to be healthy
   
5. TEST
   â†“ Execute the specific functionality that was broken
   â†“ Test edge cases and boundary conditions
   â†“ Verify the fix works as expected
   
6. VERIFY LOGS
   â†“ docker logs exai-mcp-daemon --tail 100
   â†“ Look for specific patterns confirming the fix
   â†“ Ensure no new errors were introduced
   
7. MOVE ON
   â†“ Only after complete verification
   â†“ Update task manager
   â†“ Document the fix
```

### ðŸ—ºï¸ Code Pathway Following

**How to Trace Issues Through Multiple Files:**

1. **Start with the error message:**
   ```bash
   docker logs exai-mcp-daemon --tail 200 | grep "ERROR\|Exception"
   ```

2. **Find the source file:**
   ```bash
   grep -r "error_message_text" tools/ src/ utils/
   ```

3. **Trace the call stack:**
   - Look at the file/line number in the error
   - Find the function that called it
   - Trace backwards to the entry point
   - Map out the complete pathway

4. **Example from our session:**
   ```
   Error: Failed to read /app/c:\Project\...
   â†“
   orchestration.py:523 - cache.read_file() exception handler
   â†“
   file_cache.py:118 - normalize_path() call
   â†“
   performance_optimizer.py:207 - normalize_path() implementation
   â†“
   ROOT CAUSE: Regex not matching Windows paths correctly
   ```

### ðŸ“Š Docker Log Verification Patterns

**What to Look For:**
```bash
# Success patterns
âœ… "INFO: Saved conversation"
âœ… "INFO: [CONTEXT_PRUNING] Loaded X messages"
âœ… "INFO: Uploaded file: filename -> file_id"
âœ… "HTTP/2 200 OK" or "HTTP/2 201 Created"

# Failure patterns
âŒ "WARNING: Failed to read"
âŒ "ERROR:" or "CRITICAL:"
âŒ "Exception:" or "Traceback:"
âŒ "HTTP/2 4XX" or "HTTP/2 5XX"
âŒ "Circuit breaker triggered"
âŒ "Confidence stagnant at 'low' for 3 steps"
```

**Verification Commands:**
```bash
# Check for specific error patterns
docker logs exai-mcp-daemon --tail 100 | grep -i "error\|exception\|failed"

# Check for specific success patterns
docker logs exai-mcp-daemon --tail 100 | grep -i "success\|saved\|uploaded"

# Follow logs in real-time during testing
docker logs -f exai-mcp-daemon

# Check specific conversation ID
docker logs exai-mcp-daemon --tail 200 | grep "conversation_id_here"
```

---

## 3. Critical Mindset: The Investigative Approach

### ðŸŽ¯ Non-Negotiable Principles

**PRINCIPLE #1: NEVER IGNORE DISCOVERED ERRORS**
```
âŒ BAD: "I see a path normalization issue, but I'm focused on timeouts, 
         so I'll ignore it for now and just document it."

âœ… GOOD: "While investigating the timeout issue, I noticed path normalization 
          is failing. Let me fix this FIRST since it could be causing secondary 
          issues. I'll use the debug tool to trace the root cause, implement a 
          fix, rebuild, and verify in the logs before returning to the timeout issue."
```

**PRINCIPLE #2: FIX IMMEDIATELY, NOT LATER**
- "Later" never comes
- Small issues compound into big problems
- Fixing now prevents future debugging sessions
- Each fix makes the system more stable

**PRINCIPLE #3: TEST THOROUGHLY BEFORE MOVING ON**
- Don't just check that errors disappear
- Verify correct behavior appears
- Test edge cases
- Check Docker logs for confirmation

**PRINCIPLE #4: BE THOROUGH AND INVESTIGATIVE**
- Don't make assumptions
- Follow evidence
- Trace root causes
- Understand the "why" not just the "what"

### ðŸ”¬ The Investigative Mindset

**Questions to Ask Yourself:**
1. What is the ACTUAL error message? (Not what I think it is)
2. Where in the code does this error originate?
3. What code path leads to this error?
4. What are the upstream dependencies?
5. What are the downstream effects?
6. Have I verified this in Docker logs?
7. Have I tested the fix thoroughly?
8. Could this fix introduce new issues?

**Red Flags That Indicate Superficial Work:**
- âš ï¸ "I think this might work" (without testing)
- âš ï¸ "The error is gone" (without verifying correct behavior)
- âš ï¸ "I'll document this for later" (instead of fixing now)
- âš ï¸ "This looks like it's working" (without Docker log verification)
- âš ï¸ "I'll skip this error for now" (ignoring discovered issues)

---

## 4. Current System State

### âœ… Recent Fixes (Completed This Session)

**Bug #1: Context Window Explosion**
- **Impact:** 97% token reduction (139K â†’ 3K)
- **Fix:** Strip embedded conversation history before saving
- **Files:** `tools/simple/base.py`, `tools/chat.py`, `tools/simple/mixins/continuation_mixin.py`

**Bug #2: Storage Fragmentation**
- **Impact:** Context preserved across all tools
- **Fix:** Unified all tools to use Supabase storage
- **Files:** `tools/chat.py`

**Bug #3: Duplicate Message Saving**
- **Impact:** Clean Supabase data, no duplicates
- **Fix:** Removed duplicate saving logic
- **Files:** `tools/simple/base.py`, `tools/simple/mixins/continuation_mixin.py`

**Bug #4: Path Handling**
- **Impact:** Windows paths work in Docker
- **Fix:** Docker-aware path normalization
- **Files:** `tools/workflow/performance_optimizer.py`

**Bug #5: Circuit Breaker**
- **Impact:** Prevents infinite loops
- **Fix:** Abort after 3 consecutive failures
- **Files:** `tools/workflow/orchestration.py`

**Bug #6: Assistant Response Not Saved on First Turn**
- **Impact:** Context preserved on first turn
- **Fix:** Conditional saving + deferred save after conversation creation
- **Files:** `tools/chat.py`, `tools/simple/base.py`, `tools/simple/mixins/continuation_mixin.py`

**Bug #7: Dict-to-ThreadContext Conversion Missing**
- **Impact:** Supabase data usable
- **Fix:** Implemented complete dict-to-ThreadContext conversion
- **Files:** `utils/conversation/threads.py`

**Bug #8: Path Normalization Regex Not Matching**
- **Impact:** Windows paths normalized correctly
- **Fix:** Convert backslashes before regex matching
- **Files:** `tools/workflow/performance_optimizer.py`

### ðŸŽ¯ Remaining Priority Tasks

**HIGH PRIORITY:**
1. **Test #3: Concurrent EXAI Operations**
   - Multiple simultaneous tool executions
   - Verify no cross-session blocking
   - Monitor semaphore health

2. **Test #4: Large File Handling**
   - Test with files >5MB
   - Verify circuit breaker works
   - Check memory usage

3. **Test #5: Error Recovery**
   - Test circuit breaker with intentional failures
   - Verify graceful degradation

4. **Fix Kimi Timeout Cascade**
   - Retries at exactly 180s intervals
   - Determine if timeout too short or API issue
   - Implement adaptive timeout

5. **Implement Concurrent Session Architecture**
   - Design proper multi-session parallelization
   - Prevent connection blocking
   - Reference: `ARCHITECTURAL_UPGRADE_REQUEST_2025-10-19.md`

6. **Complete Load Testing Suite**
   - Run baseline/stress/extreme tests
   - Generate comprehensive reports
   - Monitor Prometheus metrics

### âš ï¸ Known System Quirks

**ðŸš¨ CRITICAL: ALL Workflow Tools Infinite Loop Vulnerability (Bug #10)**
- **Symptom:** "Confidence stagnant at 'X' for 3 steps" repeating endlessly
- **Cause:** Circuit breaker in `orchestration.py` LOGS warning but DOES NOT ABORT (line 621: "Don't stop, but log the concern")
- **Affected Tools:** debug, codereview, analyze, thinkdeep, refactor, secaudit, testgen, precommit, docgen (ALL workflow tools!)
- **Impact:** Tools loop through up to 50 steps, waste tokens, can cause WebSocket drops
- **Solution:**
  - **SAFEST:** Use `chat_EXAI-WS` instead of workflow tools
  - **IF using workflow tools:** Monitor Docker logs, set `confidence="certain"` to force early termination
  - **NEVER use thinkdeep** - most affected by this bug
- **Status:** UNFIXED - needs immediate fix in `tools/workflow/orchestration.py` line 621
- **Evidence:** See `BUG_10_WORKFLOW_TOOLS_INFINITE_LOOP_2025-10-19.md` for full analysis
- **Fix:** Change line 621 from `# Don't stop, but log the concern` to `return False`

**ðŸš¨ CRITICAL: Thinkdeep Most Affected (Bug #9 - subset of Bug #10)**
- **Evidence:** See Docker logs 2025-10-19 23:13:45 - ran 24 steps with no progress
- **User Report:** "Additionally i think debug is broken as well" - confirmed Bug #10 affects all tools

**ðŸš¨ CRITICAL: First EXAI Call Latency (Bug #11)**
- **Symptom:** First call to ANY EXAI tool in a new conversation takes 1+ minutes to respond
- **Cause:** Unknown - needs investigation (possible: conversation initialization, Supabase setup, model loading, cache warming)
- **Impact:** Poor user experience, appears unresponsive, causes frustration
- **Workaround:** Be patient on first call, subsequent calls in same conversation are fast
- **Status:** UNFIXED - needs investigation
- **User Report:** "always the first call when a new chat/conversation is created it appears at least a minute most times it takes for us to get a response back from exai"
- **Investigation Needed:**
  - Check conversation initialization time in Supabase
  - Check model loading/cache warming time
  - Check provider connection establishment time
  - Profile first vs subsequent call performance
  - Add timing logs to identify bottleneck

**WebSocket Connection Drops:**
- **Symptom:** `no close frame received or sent`
- **Cause:** Connection timeout, network issue, OR infinite loop in workflow tools
- **Solution:** Retry the operation, check Docker logs for infinite loop patterns

**Auto-Execution Can Loop:**
- **Symptom:** "Confidence stagnant at 'low' for 3 steps"
- **Cause:** Workflow tool can't make progress
- **Solution:** Circuit breaker should trigger, but may not work for all tools

**Model Selection Issues:**
- **Symptom:** Extended hang times with `model="auto"`
- **Cause:** Model selection logic can stall
- **Solution:** Always use explicit model like `glm-4.6`

---

## 5. Practical Workflow Examples

### ðŸ“– Example 1: Handling a New Bug Report

**Scenario:** User reports "EXAI forgets context after first turn"

**Step-by-Step:**
```
1. INVESTIGATE
   - Reproduce the issue with a test conversation
   - Check Docker logs for the conversation_id
   - Look for message saving patterns

2. CONSULT EXAI
   debug_EXAI-WS(
       step="Investigate why assistant response not saved on first turn",
       findings="Supabase shows only 1 message (user) instead of 2 (user + assistant)",
       hypothesis="Assistant response not being saved to Supabase",
       relevant_files=["tools/chat.py", "tools/simple/mixins/continuation_mixin.py"],
       model="glm-4.6"
   )

3. FIX
   - Implement conditional saving logic
   - Add deferred save after conversation creation
   - Update dict-to-ThreadContext conversion

4. REBUILD
   docker-compose down
   docker-compose up -d --build

5. TEST
   - Create new conversation with continuation_id
   - Ask EXAI to remember something
   - Continue conversation asking what was remembered
   - Verify EXAI remembers correctly

6. VERIFY LOGS
   docker logs exai-mcp-daemon --tail 100 | grep "conversation_id"
   # Look for: "Saved conversation", "Loaded 2 messages", "Reconstructed context"

7. MOVE ON
   - Update task manager
   - Document the fix
   - Move to next task
```

### ðŸ“– Example 2: When Multiple Issues Appear

**Scenario:** While fixing timeout issue, discover path normalization bug

**Correct Approach:**
```
1. PAUSE the timeout investigation
2. FIX the path normalization issue IMMEDIATELY
   - It could be causing secondary issues
   - It's blocking workflow tools
   - It's a critical bug
3. TEST the path normalization fix thoroughly
4. VERIFY in Docker logs
5. DOCUMENT the fix
6. RETURN to timeout investigation
```

**Why This Matters:**
- Path normalization affects multiple systems
- Fixing it now prevents future debugging
- It could be related to the timeout issue
- Small issues compound into big problems

---

## 6. Emergency Procedures

### ðŸš¨ When EXAI Tools Fail

**Symptom:** WebSocket connection drops, no response, or error

**Procedure:**
```
1. Check Docker logs immediately
   docker logs exai-mcp-daemon --tail 50

2. Look for specific error patterns
   - "ERROR:" or "Exception:"
   - "Circuit breaker triggered"
   - "Confidence stagnant"

3. Retry with modified parameters
   - Try different model (glm-4.6 â†’ glm-4.5-flash)
   - Reduce file count in relevant_files
   - Simplify the step description

4. If still failing, use alternative approach
   - Switch to chat_EXAI-WS for quick consultation
   - Manual code analysis if all tools fail
   - Document the tool failure

5. Report the issue
   - Note which tool failed
   - Note the parameters used
   - Note the error message
```

### ðŸ”§ When System Becomes Unstable

**Symptom:** Container crashes, repeated errors, memory issues

**Procedure:**
```
1. Check Docker logs for crash patterns
   docker logs exai-mcp-daemon --tail 200 | grep -i "error\|critical\|exception"

2. Restart the container
   docker-compose down
   docker-compose up -d

3. Wait for healthy status
   docker ps -a | grep exai-mcp-daemon
   # Wait for "(healthy)" status

4. Verify core functionality
   - Test simple chat call
   - Check Supabase connection
   - Verify Redis connection

5. If instability persists
   - Review recent changes
   - Consider reverting last commit
   - Consult EXAI for architectural issues
```

---

## 7. Success Metrics

### âœ… Your Work is Successful When:

**Code Quality:**
- âœ… All fixes are verified in Docker logs
- âœ… No new errors are introduced
- âœ… System stability is maintained or improved
- âœ… Code is well-documented with comments

**Testing:**
- âœ… Fixes are tested thoroughly with edge cases
- âœ… Docker logs confirm expected behavior
- âœ… No regressions in existing functionality
- âœ… Performance is maintained or improved

**Documentation:**
- âœ… Fixes are documented in markdown files
- âœ… Task manager is updated
- âœ… Code comments explain the "why"
- âœ… Next agent can continue seamlessly

**Mindset:**
- âœ… Discovered issues were fixed immediately
- âœ… Investigation was thorough and systematic
- âœ… Evidence-based decisions, not assumptions
- âœ… Root causes identified, not just symptoms

---

## ðŸŽ“ Final Words

**Remember:**
> The goal is not just to fix issues, but to improve the overall system robustness through systematic, thorough investigation and testing.

**Key Takeaways:**
1. Use EXAI tools extensively - they're powerful when used correctly
2. Follow the 7-step debugging process religiously
3. Never ignore discovered errors - fix them immediately
4. Verify everything in Docker logs
5. Be thorough and investigative, not superficial

**This handoff guide represents our collective learning from fixing 8 critical bugs in a single session. Follow it rigorously, and you'll be effective in continuing the EXAI MCP Server project.**

---

**Good luck, and happy debugging! ðŸš€**

