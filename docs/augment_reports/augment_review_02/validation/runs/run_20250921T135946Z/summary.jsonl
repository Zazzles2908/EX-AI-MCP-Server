{"tool": "chat", "label": "chat_kimi_a", "ok": true, "error": null, "preview": "{\"status\": \"continuation_available\", \"content\": \"=== PROGRESS ===\\n[PROGRESS] chat: Starting execution\\n[PROGRESS] chat: Request validated\\n[PROGRESS] chat: Model/context ready: kimi-k2-0905-preview\\n"}
{"tool": "chat", "label": "chat_kimi_b", "ok": true, "error": null, "preview": "{\"status\": \"continuation_available\", \"content\": \"=== PROGRESS ===\\n[PROGRESS] chat: Starting execution\\n[PROGRESS] chat: Request validated\\n[PROGRESS] chat: Model/context ready: kimi-k2-0905-preview\\n"}
{"tool": "chat", "label": "chat_glm_flash", "ok": true, "error": null, "preview": "{\"status\": \"continuation_available\", \"content\": \"=== PROGRESS ===\\n[PROGRESS] chat: Starting execution\\n[PROGRESS] chat: Request validated\\n[PROGRESS] chat: Model/context ready: glm-4.5-flash\\n[PROGRE"}
{"tool": "__meta__", "label": "ws_error", "ok": false, "error": "sent 1011 (internal error) keepalive ping timeout; no close frame received"}
{"tool": "cli_extras", "label": "embeddings_cleanup", "ok": true, "preview": "{\"embeddings\": null, \"cleanup\": {\"rc\": 0, \"stdout_len\": 28, \"stderr_len\": 0}}"}
