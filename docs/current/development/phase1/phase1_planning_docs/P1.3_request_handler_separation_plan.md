# Phase 1.3: Request Handler Separation Plan

**Target**: `src/server/handlers/request_handler.py` (1,344 lines)  
**Goal**: Split into 3 focused modules (~400-450 lines each)  
**Status**: Planning

---

## Current Structure Analysis

### Overview
The file contains ONE massive function `handle_call_tool()` spanning **1,275 lines** (lines 70-1341), plus:
- Module-level imports and configuration (lines 1-69)
- Helper function definitions (embedded within main function)

### Main Function Sections (handle_call_tool)

#### Lines 70-220: Setup & Initialization
- Function signature and docstring
- Request ID generation
- Tool registry building
- Thinking tool aliasing/rerouting
- Activity logging setup
- JSONL event initialization
- Watchdog and timeout configuration
- Monitor function definition (`_execute_with_monitor`)

#### Lines 220-400: Context Reconstruction & Preprocessing
- Thread context reconstruction (continuation_id handling)
- Session cache integration
- Consensus tool auto-model selection
- Tool name normalization
- Client allow/deny list enforcement

#### Lines 400-700: Model Resolution & Routing
- Auto model routing logic (`_route_auto_model` function)
- Model context resolution
- Temperature validation
- Provider configuration
- Model selection for different tool types

#### Lines 700-1100: Tool Execution
- Progress capture
- Tool execution with monitoring
- Error handling
- Response processing
- Continuation offer generation

#### Lines 1100-1320: Response Formatting & Cleanup
- Follow-up instructions
- Progress log attachment
- Session cache updates
- Activity logging
- Response return

#### Lines 1320-1341: Unknown Tool Handling
- Tool name suggestions
- Error responses

---

## Proposed 3-Module Split

### Module 1: `request_preprocessing.py` (~450 lines)
**Purpose**: Request validation, context reconstruction, and preprocessing

**Contents**:
- **Setup & Initialization**:
  - Request ID generation
  - Tool registry building
  - Thinking tool aliasing/rerouting
  - Activity logging setup
  - JSONL event initialization
  
- **Context Reconstruction**:
  - Thread context reconstruction (continuation_id)
  - Session cache integration
  - Conversation history loading
  
- **Request Normalization**:
  - Tool name normalization
  - Client allow/deny list enforcement
  - Consensus auto-model selection
  
- **Validation**:
  - Argument validation
  - Permission checks

**Functions**:
- `initialize_request(name, arguments) -> RequestContext`
- `reconstruct_conversation_context(arguments) -> dict`
- `validate_tool_access(name, client_info) -> bool`
- `normalize_tool_name(name, tool_map) -> str`
- `setup_consensus_models(arguments) -> dict`

**Lines**: ~450  
**Responsibility**: Request preprocessing and validation

---

### Module 2: `model_resolution.py` (~400 lines)
**Purpose**: Model selection, routing, and context resolution

**Contents**:
- **Auto Model Routing**:
  - Tool-specific model selection logic
  - Step-aware heuristics for workflows
  - Provider-specific routing (Kimi, GLM)
  
- **Model Context Resolution**:
  - Model context creation
  - Temperature validation
  - Provider configuration
  
- **Routing Logic**:
  - Simple vs deep model selection
  - Workflow step analysis
  - Thinking mode detection

**Functions**:
- `route_auto_model(tool_name, requested_model, args) -> str`
- `resolve_model_context(tool, arguments) -> ModelContext`
- `validate_temperature(temperature, model_context) -> float`
- `select_model_for_tool(tool_name, step_info) -> str`

**Lines**: ~400  
**Responsibility**: Model selection and routing

---

### Module 3: `tool_execution.py` (~450 lines)
**Purpose**: Tool execution, monitoring, and response handling

**Contents**:
- **Execution Monitoring**:
  - Watchdog and timeout management
  - Heartbeat monitoring
  - Progress capture
  
- **Tool Execution**:
  - Tool invocation with monitoring
  - Error handling and recovery
  - Cancellation handling
  
- **Response Processing**:
  - Response formatting
  - Continuation offer generation
  - Follow-up instructions
  - Progress log attachment
  
- **Cleanup & Logging**:
  - Session cache updates
  - Activity logging
  - Event recording

**Functions**:
- `execute_with_monitor(tool, arguments, timeout) -> list[TextContent]`
- `create_heartbeat_monitor(name, req_id, start_time) -> Task`
- `process_tool_response(result, arguments, req_id) -> list[TextContent]`
- `generate_continuation_offer(result, arguments) -> TextContent`
- `handle_unknown_tool(name, tool_map) -> list[TextContent]`

**Lines**: ~450  
**Responsibility**: Tool execution and response handling

---

## Refactored request_handler.py (~150 lines)

**Purpose**: Main orchestration and coordination

**Structure**:
```python
from src.server.handlers.request_preprocessing import (
    initialize_request,
    reconstruct_conversation_context,
    validate_tool_access,
    normalize_tool_name,
)
from src.server.handlers.model_resolution import (
    route_auto_model,
    resolve_model_context,
)
from src.server.handlers.tool_execution import (
    execute_with_monitor,
    process_tool_response,
    handle_unknown_tool,
)

async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
    """
    Handle incoming tool execution requests from MCP clients.
    
    This is the main request dispatcher that coordinates:
    1. Request preprocessing and validation
    2. Model selection and routing
    3. Tool execution and monitoring
    4. Response processing and cleanup
    """
    # 1. Initialize and preprocess request
    request_ctx = await initialize_request(name, arguments)
    
    # 2. Reconstruct conversation context if needed
    if request_ctx.continuation_id:
        arguments = await reconstruct_conversation_context(arguments)
    
    # 3. Validate tool access
    if not validate_tool_access(request_ctx.name, request_ctx.client_info):
        return [TextContent(type="text", text=f"Tool '{name}' access denied")]
    
    # 4. Resolve model context
    model_context = await resolve_model_context(request_ctx.tool, arguments)
    
    # 5. Execute tool with monitoring
    result = await execute_with_monitor(
        request_ctx.tool,
        arguments,
        model_context,
        request_ctx.timeout
    )
    
    # 6. Process and return response
    return await process_tool_response(result, arguments, request_ctx)
```

**Lines**: ~150  
**Responsibility**: Orchestration and coordination

---

## Migration Strategy

1. **Create Module 1** (request_preprocessing.py):
   - Extract initialization logic
   - Extract context reconstruction
   - Extract validation logic
   - Create clean function interfaces

2. **Create Module 2** (model_resolution.py):
   - Extract auto model routing
   - Extract model context resolution
   - Extract temperature validation
   - Preserve routing heuristics

3. **Create Module 3** (tool_execution.py):
   - Extract execution monitoring
   - Extract tool invocation
   - Extract response processing
   - Preserve error handling

4. **Refactor request_handler.py**:
   - Import all 3 modules
   - Simplify main function to orchestration
   - Remove all implementation code
   - Keep only coordination logic

5. **Test & Validate**:
   - Run diagnostics on all files
   - Restart server
   - Verify all tools work correctly
   - Test conversation continuation
   - Test model routing

---

## Dependencies to Handle

- `src.server.context.reconstruct_thread_context`
- `src.server.utils.parse_model_option`, `get_follow_up_instructions`
- `src.server.registry_bridge.get_registry`
- `src.providers.registry.ModelProviderRegistry`
- `utils.conversation_memory`
- `utils.progress`
- `utils.cache`
- `utils.client_info`
- `utils.tool_events`

---

## Challenges & Considerations

1. **Nested Functions**: The main function contains nested helper functions that need to be extracted
2. **Shared State**: Variables like `req_id`, `_evt`, `_sink` are used across sections
3. **Error Handling**: Try/except blocks span multiple sections
4. **Async Context**: Need to preserve async/await patterns
5. **Logging**: Extensive logging throughout needs to be maintained

---

## Acceptance Criteria

- ✅ All modules under 500 lines
- ✅ Clean separation of concerns
- ✅ No duplicate code
- ✅ All tools execute correctly
- ✅ Conversation continuation works
- ✅ Model routing preserved
- ✅ Server restarts successfully
- ✅ Zero breaking changes

---

**Next Steps**: Begin implementation with Module 1 (request_preprocessing.py)

