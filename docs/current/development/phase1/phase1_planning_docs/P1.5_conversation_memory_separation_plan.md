# Phase 1.5: Conversation Memory Separation Plan

**Target**: `utils/conversation_memory.py` (1,109 lines)  
**Goal**: Split into 3 focused modules (~300-400 lines each)  
**Status**: Planning

---

## Current Structure Analysis

### Overview
The file contains 14 independent functions organized into logical groups:
- Data models (2 classes)
- Thread management (4 functions)
- File/image collection (2 functions)
- Conversation history building (1 large function + 3 helpers)
- Utility functions (2 functions)

### Function Breakdown (14 functions + 2 classes)

#### Lines 1-218: Module Header & Data Models (218 lines)
- Comprehensive module docstring (105 lines)
- Imports and configuration constants
- `ConversationTurn` class (Pydantic model)
- `ThreadContext` class (Pydantic model)
- `get_storage()` function

#### Lines 220-400: Thread Management (180 lines)
- `create_thread()` - Create new conversation thread
- `get_thread()` - Retrieve thread by ID
- `add_turn()` - Add turn to conversation
- `get_thread_chain()` - Traverse parent chain

#### Lines 443-648: File & Image Collection (205 lines)
- `get_conversation_file_list()` - Extract files with newest-first priority
- `get_conversation_image_list()` - Extract images with newest-first priority
- `_plan_file_inclusion_by_size()` - Plan file inclusion by size

#### Lines 648-1030: Conversation History Building (382 lines)
- `build_conversation_history()` - Main history builder (large function)

#### Lines 1030-1110: Formatting & Utilities (80 lines)
- `_get_tool_formatted_content()` - Tool-specific formatting
- `_default_turn_formatting()` - Default turn formatting
- `_is_valid_uuid()` - UUID validation

---

## Proposed 3-Module Split

### Module 1: `conversation_models.py` (~250 lines)
**Purpose**: Data models and storage access

**Contents**:
- Module docstring (condensed version)
- Imports and configuration constants
- `ConversationTurn` class
- `ThreadContext` class
- `get_storage()` function
- `_is_valid_uuid()` utility

**Lines**: ~250  
**Responsibility**: Data structures and storage backend access

---

### Module 2: `conversation_threads.py` (~350 lines)
**Purpose**: Thread lifecycle management

**Contents**:
- `create_thread()` - Create new conversation thread
- `get_thread()` - Retrieve thread by ID
- `add_turn()` - Add turn to conversation
- `get_thread_chain()` - Traverse parent chain
- `get_conversation_file_list()` - Extract files with newest-first priority
- `get_conversation_image_list()` - Extract images with newest-first priority

**Lines**: ~350  
**Responsibility**: Thread CRUD operations and file/image collection

---

### Module 3: `conversation_history.py` (~450 lines)
**Purpose**: Conversation history building and formatting

**Contents**:
- `build_conversation_history()` - Main history builder
- `_plan_file_inclusion_by_size()` - Plan file inclusion
- `_get_tool_formatted_content()` - Tool-specific formatting
- `_default_turn_formatting()` - Default turn formatting

**Lines**: ~450  
**Responsibility**: History reconstruction and formatting

---

## Refactored conversation_memory.py (~100 lines)

**Purpose**: Public API and backward compatibility

**Structure**:
```python
"""
Conversation Memory for AI-to-AI Multi-turn Discussions

This module provides conversation persistence and context reconstruction.
See individual modules for detailed documentation:
- conversation_models: Data structures
- conversation_threads: Thread management
- conversation_history: History building
"""

# Re-export all public APIs for backward compatibility
from utils.conversation_models import (
    ConversationTurn,
    ThreadContext,
    get_storage,
    MAX_CONVERSATION_TURNS,
    CONVERSATION_TIMEOUT_SECONDS,
)

from utils.conversation_threads import (
    create_thread,
    get_thread,
    add_turn,
    get_thread_chain,
    get_conversation_file_list,
    get_conversation_image_list,
)

from utils.conversation_history import (
    build_conversation_history,
)

__all__ = [
    # Models
    "ConversationTurn",
    "ThreadContext",
    # Constants
    "MAX_CONVERSATION_TURNS",
    "CONVERSATION_TIMEOUT_SECONDS",
    # Thread Management
    "create_thread",
    "get_thread",
    "add_turn",
    "get_thread_chain",
    # File/Image Collection
    "get_conversation_file_list",
    "get_conversation_image_list",
    # History Building
    "build_conversation_history",
    # Storage
    "get_storage",
]
```

**Lines**: ~100  
**Responsibility**: Public API and backward compatibility

---

## Migration Strategy

1. **Create Module 1** (conversation_models.py):
   - Extract data models
   - Extract configuration constants
   - Extract storage access
   - Extract UUID validation

2. **Create Module 2** (conversation_threads.py):
   - Extract thread management functions
   - Extract file/image collection functions
   - Import models from Module 1

3. **Create Module 3** (conversation_history.py):
   - Extract history building function
   - Extract formatting helpers
   - Import models from Module 1
   - Import file collection from Module 2

4. **Refactor conversation_memory.py**:
   - Import all modules
   - Re-export public APIs
   - Maintain backward compatibility
   - Add __all__ for explicit exports

5. **Test & Validate**:
   - Run diagnostics on all files
   - Restart server
   - Test conversation continuation
   - Test cross-tool continuation
   - Verify file prioritization works

---

## Dependencies to Handle

- `pydantic.BaseModel`
- `utils.storage_backend.get_storage_backend`
- `utils.file_utils.read_file_content`
- `utils.token_utils.estimate_tokens`
- `logging`, `os`, `uuid`, `datetime`

---

## Acceptance Criteria

- ✅ All modules under 500 lines
- ✅ Clean separation of concerns
- ✅ No duplicate code
- ✅ Backward compatibility maintained
- ✅ All conversation features work
- ✅ Cross-tool continuation preserved
- ✅ File prioritization works correctly
- ✅ Server restarts successfully
- ✅ Zero breaking changes

---

**Next Steps**: Begin implementation with Module 1 (conversation_models.py)

