# Phase 1.3: request_handler.py Refactoring Plan

**File**: `src/server/handlers/request_handler.py`  
**Current Size**: 1,345 lines  
**Target Size**: ~95 lines  
**Expected Reduction**: 93% (1,250 lines)  
**Status**: READY FOR IMPLEMENTATION

---

## üìä Analysis Summary

**EXAI analyze_EXAI-WS Analysis** (Continuation ID: 1dde2c1e-790b-497e-b0df-25cb53597a42):
- **3-step systematic analysis** complete
- **Confidence**: VERY_HIGH
- **Pattern**: Matches successful base_tool refactoring (93% reduction)

**Current State**:
- Single 1,271-line `handle_call_tool()` function
- God Object anti-pattern
- 10+ distinct responsibilities mixed together
- Impossible to unit test
- High coupling, very low cohesion
- Critical tech debt

---

## üéØ Refactoring Strategy

### 8-Module Split

**1. request_handler_init.py** (~100 lines)
- Environment setup, imports, configuration
- Tool registry initialization
- Shared utilities
- Request ID generation

**2. request_handler_routing.py** (~150 lines)
- Tool name normalization & aliasing
- Thinking tool rerouting logic
- Client filtering (allow/deny lists)
- Unknown tool suggestions

**3. request_handler_model_resolution.py** (~250 lines)
- Centralized auto routing policy
- Step-aware heuristics (`_route_auto_model()`)
- CJK detection (`_has_cjk()`)
- Intelligent selection by tool category
- Hidden sentinel handling
- Provider validation & fallback
- `resolve_auto_model()` function

**4. request_handler_context.py** (~100 lines)
- Thread context reconstruction
- Session cache integration
- Continuation ID management
- Context injection logic

**5. request_handler_monitoring.py** (~100 lines)
- `_execute_with_monitor()` function
- Watchdog & heartbeat implementation
- Timeout handling
- Progress capture integration
- Cancellation support

**6. request_handler_execution.py** (~200 lines)
- Tool execution orchestration
- Kimi multi-file chat with GLM fallback
- Result normalization
- File size validation
- Model context creation
- Optional features (date injection, smart websearch, client defaults)

**7. request_handler_post_processing.py** (~350 lines)
- Auto-continue workflows
- Files required to continue handling
- Progress attachment
- Activity summary generation
- Session cache write-back
- Evidence tap (Kimi bridge tracing)
- JSONL telemetry

**8. request_handler.py** (MAIN, ~95 lines)
- Thin orchestrator
- Delegates to specialized modules
- Clean, readable main flow
- Maintains public API

---

## üìù Detailed Module Breakdown

### Module 1: request_handler_init.py

**Purpose**: Centralize initialization logic

**Contents**:
- Import statements (lazy imports preserved)
- Environment flag setup (THINK_ROUTING_ENABLED)
- Provider configuration guards
- Test override shims
- Tool registry building function
- Request ID generation
- Shared utility functions

**Key Functions**:
```python
def initialize_request(name: str, arguments: dict) -> tuple[str, dict, dict]:
    """Initialize request with ID, tool map, and event tracking."""
    
def build_tool_registry() -> dict:
    """Build dynamic tool registry and return active tool map."""
    
def setup_monitoring_config() -> dict:
    """Load watchdog and timeout configuration from env."""
```

### Module 2: request_handler_routing.py

**Purpose**: Handle tool name resolution and filtering

**Contents**:
- Tool name normalization (case handling)
- Thinking tool aliasing (`deepthink` ‚Üí `thinkdeep`)
- Client allow/deny list enforcement
- Unknown tool suggestions (difflib)

**Key Functions**:
```python
def normalize_tool_name(name: str, tool_map: dict) -> str:
    """Normalize tool name and apply aliasing rules."""
    
def apply_thinking_reroute(name: str, tool_map: dict) -> str:
    """Reroute thinking-related tool names if enabled."""
    
def check_client_filters(name: str) -> Optional[str]:
    """Check allow/deny lists, return error message if blocked."""
    
def suggest_tool_name(name: str, tool_map: dict) -> Optional[str]:
    """Suggest close matches for unknown tool names."""
```

### Module 3: request_handler_model_resolution.py

**Purpose**: Centralize all model resolution logic

**Contents**:
- `_route_auto_model()` - Step-aware routing
- `resolve_auto_model()` - Legacy auto selection
- `_has_cjk()` - CJK content detection
- Intelligent selection by tool category
- Hidden sentinel handling
- Provider validation & fallback

**Key Functions**:
```python
def route_auto_model(tool_name: str, requested: str, args: dict) -> str:
    """Centralized model:auto routing policy with step-aware heuristics."""
    
def resolve_auto_model_legacy(args: dict, tool_obj) -> str:
    """Backward-compatible auto model selection."""
    
def validate_and_fallback_model(model_name: str, tool_category) -> str:
    """Validate model availability and apply graceful fallback."""
    
def has_cjk_content(text: str) -> bool:
    """Detect CJK characters in text."""
```

### Module 4: request_handler_context.py

**Purpose**: Manage conversation context and caching

**Contents**:
- Thread context reconstruction
- Session cache integration
- Continuation ID handling
- Consensus auto-model selection

**Key Functions**:
```python
async def reconstruct_context(arguments: dict) -> dict:
    """Reconstruct thread context if continuation_id present."""
    
def integrate_session_cache(arguments: dict) -> dict:
    """Inject cached context hints if available."""
    
def auto_select_consensus_models(arguments: dict) -> dict:
    """Auto-select models for consensus tool if not provided."""
```

### Module 5: request_handler_monitoring.py

**Purpose**: Execution monitoring and progress tracking

**Contents**:
- `_execute_with_monitor()` wrapper
- Heartbeat task implementation
- Timeout handling
- Progress capture
- JSONL event recording

**Key Functions**:
```python
async def execute_with_monitor(coro_factory, name: str, req_id: str, config: dict):
    """Execute tool with monitoring, heartbeat, and timeout."""
    
async def heartbeat_task(name: str, req_id: str, start_time: float, config: dict):
    """Background heartbeat for long-running operations."""
```

### Module 6: request_handler_execution.py

**Purpose**: Tool execution orchestration

**Contents**:
- Tool execution logic
- Kimi/GLM fallback handling
- Result normalization
- File size validation
- Model context creation
- Optional features (date, websearch, client defaults)

**Key Functions**:
```python
async def execute_tool(tool, arguments: dict, model_context, monitoring_config: dict) -> list:
    """Execute tool with pre-resolved model context."""
    
async def execute_with_fallback(tool, glm_tool, arguments: dict, monitoring_config: dict) -> list:
    """Execute Kimi tool with GLM fallback on structured failure."""
    
def create_model_context(model_name: str, model_option: str) -> ModelContext:
    """Create model context with resolved model and option."""
    
def inject_optional_features(arguments: dict, tool_name: str) -> dict:
    """Inject date, websearch, and client-aware defaults."""
```

### Module 7: request_handler_post_processing.py

**Purpose**: Post-execution processing and telemetry

**Contents**:
- Files required to continue
- Auto-continue workflows
- Progress attachment
- Activity summary generation
- Session cache write-back
- Evidence tap

**Key Functions**:
```python
async def handle_files_required(result: list, arguments: dict, tool, monitoring_config: dict) -> list:
    """Handle tools requesting files to continue."""
    
async def auto_continue_workflows(result: list, arguments: dict, tool, model_name: str, monitoring_config: dict) -> tuple[list, int]:
    """Auto-continue workflow tools if enabled."""
    
def attach_progress_and_summary(result: list, arguments: dict, name: str, model_name: str, req_id: str, start_time: float, steps: int) -> list:
    """Attach progress log and activity summary to result."""
    
def write_session_cache(arguments: dict):
    """Write-back compact summary to session cache."""
```

### Module 8: request_handler.py (MAIN)

**Purpose**: Thin orchestrator maintaining public API

**Contents**:
- Main `handle_call_tool()` function (~95 lines)
- Delegates to specialized modules
- Clean, readable flow
- Preserves all functionality

**Structure**:
```python
async def handle_call_tool(name: str, arguments: dict) -> list[TextContent]:
    # 1. Initialize
    req_id, tool_map, monitoring_config = initialize_request(name, arguments)
    
    # 2. Route & filter
    name = normalize_and_route_tool(name, tool_map)
    if error := check_client_filters(name):
        return [TextContent(type="text", text=error)]
    
    # 3. Handle tool execution
    if name in tool_map:
        # 3a. Reconstruct context
        arguments = await reconstruct_context(arguments)
        arguments = integrate_session_cache(arguments)
        
        # 3b. Resolve model
        model_name = resolve_model(name, arguments, tool_map[name])
        model_context = create_model_context(model_name)
        
        # 3c. Execute
        result = await execute_tool_with_monitoring(...)
        
        # 3d. Post-process
        result = await post_process_result(result, arguments, ...)
        
        return result
    else:
        return handle_unknown_tool(name, tool_map)
```

---

## ‚úÖ Implementation Checklist

### Phase 1: Create Helper Modules (7 files)
- [ ] Create `request_handler_init.py`
- [ ] Create `request_handler_routing.py`
- [ ] Create `request_handler_model_resolution.py`
- [ ] Create `request_handler_context.py`
- [ ] Create `request_handler_monitoring.py`
- [ ] Create `request_handler_execution.py`
- [ ] Create `request_handler_post_processing.py`

### Phase 2: Refactor Main File
- [ ] Create backup: `request_handler_BACKUP.py`
- [ ] Import from new modules
- [ ] Simplify `handle_call_tool()` to delegate
- [ ] Remove extracted code
- [ ] Verify line count (~95 lines)

### Phase 3: Testing
- [ ] Restart server
- [ ] Test simple tool call (chat)
- [ ] Test workflow tool (analyze)
- [ ] Test continuation (with continuation_id)
- [ ] Test model resolution (auto)
- [ ] Test Kimi fallback
- [ ] Verify all existing functionality

### Phase 4: Documentation
- [ ] Create completion report
- [ ] Update session summary
- [ ] Document any issues encountered

---

## üéØ Expected Benefits

**Maintainability**:
- ‚úÖ 93% line reduction (1,345 ‚Üí ~95)
- ‚úÖ Clear separation of concerns
- ‚úÖ Testable modules
- ‚úÖ Easier to understand and modify

**Quality**:
- ‚úÖ Reduced coupling
- ‚úÖ Improved cohesion
- ‚úÖ Better error isolation
- ‚úÖ Easier debugging

**Scalability**:
- ‚úÖ Team collaboration friendly
- ‚úÖ Parallel development possible
- ‚úÖ Easier to add features
- ‚úÖ Better performance potential

---

## ‚ö†Ô∏è Risk Mitigation

**Low Risk** - Pattern proven successful:
- base_tool.py: 93% reduction ‚úÖ
- glm.py: 74.1% reduction ‚úÖ
- kimi.py: 73.6% reduction ‚úÖ

**Mitigation Strategies**:
1. Create backup before changes
2. Preserve lazy imports (avoid circular dependencies)
3. Maintain all error handling
4. Test incrementally
5. Zero breaking changes required

---

**Status**: READY FOR IMPLEMENTATION  
**Confidence**: VERY_HIGH  
**Next Step**: Begin Phase 1 - Create helper modules

