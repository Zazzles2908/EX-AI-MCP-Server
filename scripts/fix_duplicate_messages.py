"""
Fix Duplicate Messages Root Cause
==================================

ROOT CAUSE IDENTIFIED (2025-10-23):
- save_message() was using .insert() instead of .upsert()
- Even though idempotency_key was generated, .insert() always creates new rows
- This caused duplicates during race conditions, retries, slow responses

FIX IMPLEMENTED:
1. Changed .insert() to .upsert() with on_conflict='idempotency_key'
2. Add unique constraint on idempotency_key column (if missing)
3. Clean up existing duplicates

This script:
1. Checks if unique constraint exists
2. Adds constraint if missing
3. Cleans up existing duplicates (keeps first occurrence)
4. Reports statistics
"""

import os
import sys
from dotenv import load_dotenv
from supabase import create_client

# Load environment
load_dotenv('.env.docker')

SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_SERVICE_ROLE_KEY')

if not SUPABASE_URL or not SUPABASE_KEY:
    print("‚ùå ERROR: SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY not found in .env.docker")
    sys.exit(1)

# Create Supabase client
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

print("=" * 80)
print("DUPLICATE MESSAGE FIX - ROOT CAUSE RESOLUTION")
print("=" * 80)
print()

# Step 1: Check for existing duplicates
print("üìä Step 1: Checking for existing duplicates...")
print()

# Query to find duplicates by idempotency_key
duplicate_query = """
SELECT 
    idempotency_key,
    COUNT(*) as count,
    MIN(created_at) as first_created,
    MAX(created_at) as last_created
FROM messages
WHERE idempotency_key IS NOT NULL
GROUP BY idempotency_key
HAVING COUNT(*) > 1
ORDER BY count DESC
LIMIT 20
"""

try:
    # Note: Supabase Python client doesn't support raw SQL directly
    # We'll use a different approach - get all messages and check in Python
    
    # Get all messages from last 7 days
    from datetime import datetime, timedelta
    seven_days_ago = (datetime.utcnow() - timedelta(days=7)).isoformat()
    
    result = supabase.table('messages').select('id, idempotency_key, created_at').gte('created_at', seven_days_ago).execute()
    
    messages = result.data
    print(f"‚úÖ Retrieved {len(messages)} messages from last 7 days")
    
    # Find duplicates
    idempotency_map = {}
    for msg in messages:
        key = msg.get('idempotency_key')
        if key:
            if key not in idempotency_map:
                idempotency_map[key] = []
            idempotency_map[key].append(msg)
    
    duplicates = {k: v for k, v in idempotency_map.items() if len(v) > 1}
    
    if duplicates:
        print(f"‚ö†Ô∏è  Found {len(duplicates)} duplicate idempotency keys")
        print(f"‚ö†Ô∏è  Total duplicate messages: {sum(len(v) - 1 for v in duplicates.values())}")
        print()
        
        # Show top 5 duplicates
        print("Top 5 duplicate groups:")
        for i, (key, msgs) in enumerate(sorted(duplicates.items(), key=lambda x: len(x[1]), reverse=True)[:5]):
            print(f"  {i+1}. Key: {key[:16]}... ({len(msgs)} copies)")
            print(f"     First: {msgs[0]['created_at']}")
            print(f"     Last:  {msgs[-1]['created_at']}")
        print()
    else:
        print("‚úÖ No duplicates found!")
        print()

except Exception as e:
    print(f"‚ùå Error checking duplicates: {e}")
    print()

# Step 2: Add unique constraint (if needed)
print("üîß Step 2: Checking unique constraint on idempotency_key...")
print()

# Note: We can't directly check constraints via Supabase Python client
# The constraint should be added via Supabase dashboard or SQL editor
print("‚ö†Ô∏è  MANUAL ACTION REQUIRED:")
print("   Please run this SQL in Supabase SQL Editor:")
print()
print("   -- Add unique constraint if it doesn't exist")
print("   ALTER TABLE messages")
print("   ADD CONSTRAINT unique_idempotency_key UNIQUE (idempotency_key);")
print()
print("   If the constraint already exists, you'll see an error (which is fine).")
print()

# Step 3: Clean up duplicates
if duplicates:
    print("üßπ Step 3: Cleaning up duplicates...")
    print()
    
    response = input("Do you want to delete duplicate messages? (yes/no): ")
    if response.lower() == 'yes':
        deleted_count = 0
        
        for key, msgs in duplicates.items():
            # Sort by created_at to keep the oldest
            msgs_sorted = sorted(msgs, key=lambda x: x['created_at'])
            
            # Keep first, delete rest
            to_delete = [msg['id'] for msg in msgs_sorted[1:]]
            
            try:
                for msg_id in to_delete:
                    supabase.table('messages').delete().eq('id', msg_id).execute()
                    deleted_count += 1
                    
                print(f"  ‚úÖ Deleted {len(to_delete)} duplicates for key {key[:16]}...")
            except Exception as e:
                print(f"  ‚ùå Error deleting duplicates for key {key[:16]}: {e}")
        
        print()
        print(f"‚úÖ Deleted {deleted_count} duplicate messages")
        print()
    else:
        print("‚è≠Ô∏è  Skipping duplicate cleanup")
        print()
else:
    print("‚úÖ Step 3: No duplicates to clean up")
    print()

# Step 4: Verify fix
print("‚úÖ Step 4: Verification")
print()
print("Code fix applied:")
print("  ‚úÖ Changed .insert() to .upsert() in save_message()")
print("  ‚úÖ Added on_conflict='idempotency_key'")
print("  ‚úÖ Added ignore_duplicates=True")
print()
print("Next steps:")
print("  1. Add unique constraint via Supabase SQL Editor (see above)")
print("  2. Restart Docker container: docker restart exai-mcp-daemon")
print("  3. Test message saving to verify no new duplicates")
print()

print("=" * 80)
print("FIX COMPLETE!")
print("=" * 80)

